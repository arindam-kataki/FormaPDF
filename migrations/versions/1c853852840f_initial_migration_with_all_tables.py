"""Initial migration with all tables

Revision ID: 1c853852840f
Revises: 
Create Date: 2025-08-06 15:42:06.256158

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '1c853852840f'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Apply database schema changes."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('assembly_notes',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('assembly_id', sa.Integer(), nullable=False),
    sa.Column('title', sa.String(length=500), nullable=True),
    sa.Column('content', sa.Text(), nullable=False),
    sa.Column('note_type', sa.String(length=50), nullable=True),
    sa.Column('tags', postgresql.ARRAY(sa.String()), nullable=True),
    sa.Column('priority', sa.Integer(), nullable=True),
    sa.Column('is_pinned', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('created_by', sa.String(length=255), nullable=True),
    sa.ForeignKeyConstraint(['assembly_id'], ['assemblies.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_assembly_note_assembly', 'assembly_notes', ['assembly_id'], unique=False)
    op.create_index('idx_assembly_note_created', 'assembly_notes', ['created_at'], unique=False)
    op.create_index('idx_assembly_note_type', 'assembly_notes', ['note_type'], unique=False)
    op.create_table('document_embeddings',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('document_id', sa.Integer(), nullable=False),
    sa.Column('chunk_index', sa.Integer(), nullable=False),
    sa.Column('chunk_text', sa.Text(), nullable=False),
    sa.Column('chunk_tokens', sa.Integer(), nullable=True),
    sa.Column('embedding', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('embedding_model', sa.String(length=100), nullable=True),
    sa.Column('embedding_dimension', sa.Integer(), nullable=True),
    sa.Column('page_numbers', postgresql.ARRAY(sa.Integer()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('document_id', 'chunk_index', name='uq_document_chunk')
    )
    op.create_index('idx_embedding_chunk', 'document_embeddings', ['document_id', 'chunk_index'], unique=False)
    op.create_index('idx_embedding_document', 'document_embeddings', ['document_id'], unique=False)
    op.add_column('ai_conversations', sa.Column('messages', postgresql.JSONB(astext_type=sa.Text()), nullable=False))
    op.add_column('ai_conversations', sa.Column('context', sa.Text(), nullable=True))
    op.add_column('ai_conversations', sa.Column('model_parameters', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column('ai_conversations', sa.Column('total_tokens', sa.Integer(), nullable=True))
    op.add_column('ai_conversations', sa.Column('prompt_tokens', sa.Integer(), nullable=True))
    op.add_column('ai_conversations', sa.Column('completion_tokens', sa.Integer(), nullable=True))
    op.add_column('ai_conversations', sa.Column('summary', sa.Text(), nullable=True))
    op.add_column('ai_conversations', sa.Column('key_insights', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.alter_column('ai_conversations', 'ai_provider',
               existing_type=sa.VARCHAR(length=50),
               nullable=False)
    op.alter_column('ai_conversations', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('ai_conversations', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.create_index('idx_ai_conversation_annotation', 'ai_conversations', ['annotation_id'], unique=False)
    op.create_index('idx_ai_conversation_created', 'ai_conversations', ['created_at'], unique=False)
    op.create_index('idx_ai_conversation_provider', 'ai_conversations', ['ai_provider'], unique=False)
    op.drop_constraint(op.f('ai_conversations_annotation_id_fkey'), 'ai_conversations', type_='foreignkey')
    op.create_foreign_key(None, 'ai_conversations', 'annotations', ['annotation_id'], ['id'], ondelete='CASCADE')
    op.drop_column('ai_conversations', 'conversation_data')
    op.drop_column('ai_conversations', 'token_count')
    op.add_column('annotations', sa.Column('tags', postgresql.ARRAY(sa.String()), nullable=True))
    op.add_column('annotations', sa.Column('is_resolved', sa.Boolean(), nullable=True))
    op.add_column('annotations', sa.Column('priority', sa.Integer(), nullable=True))
    op.add_column('annotations', sa.Column('created_by', sa.String(length=255), nullable=True))
    op.alter_column('annotations', 'x1',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=False)
    op.alter_column('annotations', 'y1',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=False)
    op.alter_column('annotations', 'x2',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=False)
    op.alter_column('annotations', 'y2',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=False)
    op.alter_column('annotations', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('annotations', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.create_index('idx_annotation_created', 'annotations', ['created_at'], unique=False)
    op.create_index('idx_annotation_document', 'annotations', ['document_id'], unique=False)
    op.create_index('idx_annotation_page', 'annotations', ['document_id', 'page_number'], unique=False)
    op.create_index('idx_annotation_type', 'annotations', ['annotation_type'], unique=False)
    op.drop_constraint(op.f('annotations_document_id_fkey'), 'annotations', type_='foreignkey')
    op.create_foreign_key(None, 'annotations', 'documents', ['document_id'], ['id'], ondelete='CASCADE')
    op.add_column('assemblies', sa.Column('guid', sa.String(length=36), nullable=False))
    op.add_column('assemblies', sa.Column('researcher', sa.String(length=255), nullable=True))
    op.add_column('assemblies', sa.Column('research_type', sa.String(length=100), nullable=True))
    op.add_column('assemblies', sa.Column('keywords', postgresql.ARRAY(sa.String()), nullable=True))
    op.add_column('assemblies', sa.Column('last_accessed', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True))
    op.add_column('assemblies', sa.Column('ai_config', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column('assemblies', sa.Column('is_active', sa.Boolean(), nullable=False))
    op.add_column('assemblies', sa.Column('is_archived', sa.Boolean(), nullable=False))
    op.add_column('assemblies', sa.Column('document_count', sa.Integer(), nullable=False))
    op.add_column('assemblies', sa.Column('annotation_count', sa.Integer(), nullable=False))
    op.add_column('assemblies', sa.Column('ai_conversation_count', sa.Integer(), nullable=False))
    op.add_column('assemblies', sa.Column('storage_path', sa.String(length=500), nullable=True))
    op.add_column('assemblies', sa.Column('total_size_bytes', sa.Integer(), nullable=True))
    op.alter_column('assemblies', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=False)
    op.alter_column('assemblies', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('assemblies', 'settings',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.create_index('idx_assembly_active', 'assemblies', ['is_active', 'is_archived'], unique=False)
    op.create_index('idx_assembly_created', 'assemblies', ['created_at'], unique=False)
    op.create_index('idx_assembly_guid', 'assemblies', ['guid'], unique=False)
    op.create_index('idx_assembly_researcher', 'assemblies', ['researcher'], unique=False)
    op.create_unique_constraint(None, 'assemblies', ['guid'])
    op.add_column('cross_references', sa.Column('notes', sa.Text(), nullable=True))
    op.add_column('cross_references', sa.Column('confidence', sa.Float(), nullable=True))
    op.add_column('cross_references', sa.Column('created_by', sa.String(length=255), nullable=True))
    op.alter_column('cross_references', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.create_index('idx_cross_ref_source', 'cross_references', ['source_annotation_id'], unique=False)
    op.create_index('idx_cross_ref_target', 'cross_references', ['target_annotation_id'], unique=False)
    op.create_unique_constraint('uq_cross_reference', 'cross_references', ['source_annotation_id', 'target_annotation_id'])
    op.drop_constraint(op.f('cross_references_target_annotation_id_fkey'), 'cross_references', type_='foreignkey')
    op.drop_constraint(op.f('cross_references_source_annotation_id_fkey'), 'cross_references', type_='foreignkey')
    op.create_foreign_key(None, 'cross_references', 'annotations', ['target_annotation_id'], ['id'], ondelete='CASCADE')
    op.create_foreign_key(None, 'cross_references', 'annotations', ['source_annotation_id'], ['id'], ondelete='CASCADE')
    op.drop_column('cross_references', 'reference_note')
    op.add_column('documents', sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True))
    op.add_column('documents', sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column('documents', sa.Column('extracted_text', sa.Text(), nullable=True))
    op.add_column('documents', sa.Column('is_processed', sa.Boolean(), nullable=True))
    op.add_column('documents', sa.Column('is_ocr_complete', sa.Boolean(), nullable=True))
    op.add_column('documents', sa.Column('is_indexed', sa.Boolean(), nullable=True))
    op.add_column('documents', sa.Column('processing_errors', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column('documents', sa.Column('annotation_count', sa.Integer(), nullable=True))
    op.alter_column('documents', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('documents', 'last_accessed',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.create_index('idx_document_assembly', 'documents', ['assembly_id'], unique=False)
    op.create_index('idx_document_hash', 'documents', ['content_hash'], unique=False)
    op.create_index('idx_document_type', 'documents', ['file_type'], unique=False)
    op.create_index(op.f('ix_documents_content_hash'), 'documents', ['content_hash'], unique=False)
    op.create_unique_constraint('uq_assembly_document_hash', 'documents', ['assembly_id', 'content_hash'])
    op.drop_constraint(op.f('documents_assembly_id_fkey'), 'documents', type_='foreignkey')
    op.create_foreign_key(None, 'documents', 'assemblies', ['assembly_id'], ['id'], ondelete='CASCADE')
    op.drop_column('documents', 'document_metadata')
    op.add_column('user_toc', sa.Column('section_number', sa.String(length=50), nullable=True))
    op.add_column('user_toc', sa.Column('level', sa.Integer(), nullable=True))
    op.add_column('user_toc', sa.Column('entry_type', sa.String(length=50), nullable=True))
    op.add_column('user_toc', sa.Column('notes', sa.Text(), nullable=True))
    op.add_column('user_toc', sa.Column('color', sa.String(length=7), nullable=True))
    op.add_column('user_toc', sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True))
    op.alter_column('user_toc', 'order_index',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('user_toc', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.create_index('idx_toc_assembly', 'user_toc', ['assembly_id'], unique=False)
    op.create_index('idx_toc_document', 'user_toc', ['document_id'], unique=False)
    op.create_index('idx_toc_order', 'user_toc', ['assembly_id', 'order_index'], unique=False)
    op.drop_constraint(op.f('user_toc_annotation_id_fkey'), 'user_toc', type_='foreignkey')
    op.drop_constraint(op.f('user_toc_parent_id_fkey'), 'user_toc', type_='foreignkey')
    op.drop_constraint(op.f('user_toc_assembly_id_fkey'), 'user_toc', type_='foreignkey')
    op.drop_constraint(op.f('user_toc_document_id_fkey'), 'user_toc', type_='foreignkey')
    op.create_foreign_key(None, 'user_toc', 'user_toc', ['parent_id'], ['id'], ondelete='CASCADE')
    op.create_foreign_key(None, 'user_toc', 'assemblies', ['assembly_id'], ['id'], ondelete='CASCADE')
    op.create_foreign_key(None, 'user_toc', 'documents', ['document_id'], ['id'], ondelete='CASCADE')
    op.drop_column('user_toc', 'annotation_id')
    op.drop_column('user_toc', 'toc_type')
    op.drop_column('user_toc', 'description')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Revert database schema changes."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('user_toc', sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('user_toc', sa.Column('toc_type', sa.VARCHAR(length=50), autoincrement=False, nullable=True))
    op.add_column('user_toc', sa.Column('annotation_id', sa.INTEGER(), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'user_toc', type_='foreignkey')
    op.drop_constraint(None, 'user_toc', type_='foreignkey')
    op.drop_constraint(None, 'user_toc', type_='foreignkey')
    op.create_foreign_key(op.f('user_toc_document_id_fkey'), 'user_toc', 'documents', ['document_id'], ['id'])
    op.create_foreign_key(op.f('user_toc_assembly_id_fkey'), 'user_toc', 'assemblies', ['assembly_id'], ['id'])
    op.create_foreign_key(op.f('user_toc_parent_id_fkey'), 'user_toc', 'user_toc', ['parent_id'], ['id'])
    op.create_foreign_key(op.f('user_toc_annotation_id_fkey'), 'user_toc', 'annotations', ['annotation_id'], ['id'])
    op.drop_index('idx_toc_order', table_name='user_toc')
    op.drop_index('idx_toc_document', table_name='user_toc')
    op.drop_index('idx_toc_assembly', table_name='user_toc')
    op.alter_column('user_toc', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('user_toc', 'order_index',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.drop_column('user_toc', 'updated_at')
    op.drop_column('user_toc', 'color')
    op.drop_column('user_toc', 'notes')
    op.drop_column('user_toc', 'entry_type')
    op.drop_column('user_toc', 'level')
    op.drop_column('user_toc', 'section_number')
    op.add_column('documents', sa.Column('document_metadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'documents', type_='foreignkey')
    op.create_foreign_key(op.f('documents_assembly_id_fkey'), 'documents', 'assemblies', ['assembly_id'], ['id'])
    op.drop_constraint('uq_assembly_document_hash', 'documents', type_='unique')
    op.drop_index(op.f('ix_documents_content_hash'), table_name='documents')
    op.drop_index('idx_document_type', table_name='documents')
    op.drop_index('idx_document_hash', table_name='documents')
    op.drop_index('idx_document_assembly', table_name='documents')
    op.alter_column('documents', 'last_accessed',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('documents', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.drop_column('documents', 'annotation_count')
    op.drop_column('documents', 'processing_errors')
    op.drop_column('documents', 'is_indexed')
    op.drop_column('documents', 'is_ocr_complete')
    op.drop_column('documents', 'is_processed')
    op.drop_column('documents', 'extracted_text')
    op.drop_column('documents', 'metadata')
    op.drop_column('documents', 'updated_at')
    op.add_column('cross_references', sa.Column('reference_note', sa.TEXT(), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'cross_references', type_='foreignkey')
    op.drop_constraint(None, 'cross_references', type_='foreignkey')
    op.create_foreign_key(op.f('cross_references_source_annotation_id_fkey'), 'cross_references', 'annotations', ['source_annotation_id'], ['id'])
    op.create_foreign_key(op.f('cross_references_target_annotation_id_fkey'), 'cross_references', 'annotations', ['target_annotation_id'], ['id'])
    op.drop_constraint('uq_cross_reference', 'cross_references', type_='unique')
    op.drop_index('idx_cross_ref_target', table_name='cross_references')
    op.drop_index('idx_cross_ref_source', table_name='cross_references')
    op.alter_column('cross_references', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.drop_column('cross_references', 'created_by')
    op.drop_column('cross_references', 'confidence')
    op.drop_column('cross_references', 'notes')
    op.drop_constraint(None, 'assemblies', type_='unique')
    op.drop_index('idx_assembly_researcher', table_name='assemblies')
    op.drop_index('idx_assembly_guid', table_name='assemblies')
    op.drop_index('idx_assembly_created', table_name='assemblies')
    op.drop_index('idx_assembly_active', table_name='assemblies')
    op.alter_column('assemblies', 'settings',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('assemblies', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('assemblies', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=True)
    op.drop_column('assemblies', 'total_size_bytes')
    op.drop_column('assemblies', 'storage_path')
    op.drop_column('assemblies', 'ai_conversation_count')
    op.drop_column('assemblies', 'annotation_count')
    op.drop_column('assemblies', 'document_count')
    op.drop_column('assemblies', 'is_archived')
    op.drop_column('assemblies', 'is_active')
    op.drop_column('assemblies', 'ai_config')
    op.drop_column('assemblies', 'last_accessed')
    op.drop_column('assemblies', 'keywords')
    op.drop_column('assemblies', 'research_type')
    op.drop_column('assemblies', 'researcher')
    op.drop_column('assemblies', 'guid')
    op.drop_constraint(None, 'annotations', type_='foreignkey')
    op.create_foreign_key(op.f('annotations_document_id_fkey'), 'annotations', 'documents', ['document_id'], ['id'])
    op.drop_index('idx_annotation_type', table_name='annotations')
    op.drop_index('idx_annotation_page', table_name='annotations')
    op.drop_index('idx_annotation_document', table_name='annotations')
    op.drop_index('idx_annotation_created', table_name='annotations')
    op.alter_column('annotations', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('annotations', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('annotations', 'y2',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=True)
    op.alter_column('annotations', 'x2',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=True)
    op.alter_column('annotations', 'y1',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=True)
    op.alter_column('annotations', 'x1',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=True)
    op.drop_column('annotations', 'created_by')
    op.drop_column('annotations', 'priority')
    op.drop_column('annotations', 'is_resolved')
    op.drop_column('annotations', 'tags')
    op.add_column('ai_conversations', sa.Column('token_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('ai_conversations', sa.Column('conversation_data', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'ai_conversations', type_='foreignkey')
    op.create_foreign_key(op.f('ai_conversations_annotation_id_fkey'), 'ai_conversations', 'annotations', ['annotation_id'], ['id'])
    op.drop_index('idx_ai_conversation_provider', table_name='ai_conversations')
    op.drop_index('idx_ai_conversation_created', table_name='ai_conversations')
    op.drop_index('idx_ai_conversation_annotation', table_name='ai_conversations')
    op.alter_column('ai_conversations', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('ai_conversations', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('ai_conversations', 'ai_provider',
               existing_type=sa.VARCHAR(length=50),
               nullable=True)
    op.drop_column('ai_conversations', 'key_insights')
    op.drop_column('ai_conversations', 'summary')
    op.drop_column('ai_conversations', 'completion_tokens')
    op.drop_column('ai_conversations', 'prompt_tokens')
    op.drop_column('ai_conversations', 'total_tokens')
    op.drop_column('ai_conversations', 'model_parameters')
    op.drop_column('ai_conversations', 'context')
    op.drop_column('ai_conversations', 'messages')
    op.drop_index('idx_embedding_document', table_name='document_embeddings')
    op.drop_index('idx_embedding_chunk', table_name='document_embeddings')
    op.drop_table('document_embeddings')
    op.drop_index('idx_assembly_note_type', table_name='assembly_notes')
    op.drop_index('idx_assembly_note_created', table_name='assembly_notes')
    op.drop_index('idx_assembly_note_assembly', table_name='assembly_notes')
    op.drop_table('assembly_notes')
    # ### end Alembic commands ###